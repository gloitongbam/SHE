{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHE: Sentiment Hashtag Embedding Through Multitask learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['rt','amp','url','sir','day','title','shri','crore','time',\"a\", \"about\",\"above\", \"across\", \"after\", \"afterwards\", \"again\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('emb/42K_meta_mve.emb', binary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37090 37089 100\n"
     ]
    }
   ],
   "source": [
    "idx=1\n",
    "words = []\n",
    "word2idx = {}\n",
    "vectors=[]\n",
    "vect_idx=[]\n",
    "\n",
    "vectors.append(np.asarray([0]*model.vector_size))\n",
    "with open('emb/42K_meta_mve.emb', 'rb') as f:\n",
    "    for i,l in enumerate(f):\n",
    "        if i > 0:\n",
    "            line = l.decode().split()\n",
    "            if line[1] != '-nan':\n",
    "                word = line[0]\n",
    "                words.append(word)\n",
    "                word2idx[word] = idx\n",
    "                vect = line[1:]\n",
    "                vectors.append(np.asarray(vect))\n",
    "                vect_idx.append(idx)\n",
    "                idx += 1\n",
    "                \n",
    "print(len(vectors), len(word2idx), len(vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=len(vectors[0])\n",
    "vectors=np.asarray(vectors)\n",
    "vect_idx=np.array(vect_idx)\n",
    "tss=int(len(word2idx) * 0.8)   #Train-test data split 80-20 for autoencoder\n",
    "train, test = vectors[:tss][:], vectors[tss:][:]\n",
    "train_idx, test_idx = vect_idx[:tss][:], vect_idx[tss:][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load available sentiment lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=dict()\n",
    "f=open('data/Tweets_sentilexicon_final_auto', 'r')\n",
    "lines=f.readlines()\n",
    "for l in lines:\n",
    "    word=l.lower().strip().split('\\t')\n",
    "    if word[1] not in sent:\n",
    "        sent[word[1]]=[]\n",
    "    sent[word[1]].append(word[0])\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_index(wlist,word2idx):\n",
    "    ip=[]\n",
    "    for i in wlist:\n",
    "        try:\n",
    "            idx=word2idx[i]\n",
    "            ip.append(idx)\n",
    "        except:\n",
    "            pass\n",
    "    return ip\n",
    "\n",
    "def split_list(alist, wanted_parts=1):\n",
    "    length = len(alist)\n",
    "    return [ alist[i*length // wanted_parts: (i+1)*length // wanted_parts] \n",
    "             for i in range(wanted_parts) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=dict()\n",
    "\n",
    "positive = gen_index(sent['positive'],word2idx)\n",
    "negative = gen_index(sent['negative'],word2idx)\n",
    "neutral = gen_index(sent['neutral'],word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for fold \n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "print(\"Data preparation for fold \")\n",
    "\n",
    "fold=[]\n",
    "for idx in sent['positive']:\n",
    "    fold.append(idx)\n",
    "shuffle(fold)\n",
    "folds['positive']=split_list(fold, wanted_parts=10)\n",
    "\n",
    "fold=[]\n",
    "for idx in sent['negative']:\n",
    "    fold.append(idx)\n",
    "shuffle(fold)\n",
    "folds['negative']=split_list(fold, wanted_parts=10)\n",
    "\n",
    "fold=[]\n",
    "for idx in sent['neutral']:\n",
    "    fold.append(idx)\n",
    "shuffle(fold)\n",
    "folds['neutral']=split_list(fold, wanted_parts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building SHE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional,SimpleRNN,GRU,CuDNNGRU,Reshape\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Activation, Flatten, UpSampling1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from keras.models import model_from_json\n",
    "import pickle\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold begin 0\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 100)            30100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 64)             19264     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 55,864\n",
      "Trainable params: 55,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 100)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1, 100)       30100       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 100)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 100)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1, 64)        19264       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 64)        19264       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 64)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 64)           0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          6500        global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            195         global_max_pooling1d_2[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 75,323\n",
      "Trainable params: 75,323\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29671 samples, validate on 7419 samples\n",
      "Epoch 1/20\n",
      "29671/29671 [==============================] - 7s 225us/step - loss: 0.0049 - accuracy: 0.1748 - val_loss: 0.0031 - val_accuracy: 0.3231\n",
      "Epoch 2/20\n",
      "29671/29671 [==============================] - 6s 207us/step - loss: 0.0033 - accuracy: 0.2947 - val_loss: 0.0025 - val_accuracy: 0.3953\n",
      "Epoch 3/20\n",
      "29671/29671 [==============================] - 6s 213us/step - loss: 0.0030 - accuracy: 0.3239 - val_loss: 0.0023 - val_accuracy: 0.4286\n",
      "Epoch 4/20\n",
      "29671/29671 [==============================] - 6s 207us/step - loss: 0.0029 - accuracy: 0.3388 - val_loss: 0.0022 - val_accuracy: 0.4486\n",
      "Epoch 5/20\n",
      "29671/29671 [==============================] - 6s 217us/step - loss: 0.0028 - accuracy: 0.3448 - val_loss: 0.0021 - val_accuracy: 0.4598\n",
      "Epoch 6/20\n",
      "29671/29671 [==============================] - 6s 207us/step - loss: 0.0028 - accuracy: 0.3518 - val_loss: 0.0021 - val_accuracy: 0.4657\n",
      "Epoch 7/20\n",
      "29671/29671 [==============================] - 6s 203us/step - loss: 0.0028 - accuracy: 0.3581 - val_loss: 0.0020 - val_accuracy: 0.4754\n",
      "Epoch 8/20\n",
      "29671/29671 [==============================] - 6s 203us/step - loss: 0.0027 - accuracy: 0.3649 - val_loss: 0.0020 - val_accuracy: 0.4803\n",
      "Epoch 9/20\n",
      "29671/29671 [==============================] - 6s 203us/step - loss: 0.0027 - accuracy: 0.3651 - val_loss: 0.0019 - val_accuracy: 0.4867\n",
      "Epoch 10/20\n",
      "29671/29671 [==============================] - 6s 201us/step - loss: 0.0026 - accuracy: 0.3738 - val_loss: 0.0019 - val_accuracy: 0.5011\n",
      "Epoch 11/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0026 - accuracy: 0.3761 - val_loss: 0.0019 - val_accuracy: 0.5013\n",
      "Epoch 12/20\n",
      "29671/29671 [==============================] - 6s 207us/step - loss: 0.0026 - accuracy: 0.3750 - val_loss: 0.0019 - val_accuracy: 0.4968\n",
      "Epoch 13/20\n",
      "29671/29671 [==============================] - 6s 205us/step - loss: 0.0026 - accuracy: 0.3762 - val_loss: 0.0019 - val_accuracy: 0.4982\n",
      "Epoch 14/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0026 - accuracy: 0.3771 - val_loss: 0.0018 - val_accuracy: 0.5059\n",
      "Epoch 15/20\n",
      "29671/29671 [==============================] - 6s 207us/step - loss: 0.0026 - accuracy: 0.3833 - val_loss: 0.0018 - val_accuracy: 0.5082\n",
      "Epoch 16/20\n",
      "29671/29671 [==============================] - 6s 203us/step - loss: 0.0026 - accuracy: 0.3813 - val_loss: 0.0018 - val_accuracy: 0.5059\n",
      "Epoch 17/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0026 - accuracy: 0.3803 - val_loss: 0.0018 - val_accuracy: 0.5028\n",
      "Epoch 18/20\n",
      "29671/29671 [==============================] - 6s 202us/step - loss: 0.0026 - accuracy: 0.3858 - val_loss: 0.0018 - val_accuracy: 0.5067\n",
      "Epoch 19/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0025 - accuracy: 0.3885 - val_loss: 0.0018 - val_accuracy: 0.5131\n",
      "Epoch 20/20\n",
      "29671/29671 [==============================] - 6s 205us/step - loss: 0.0025 - accuracy: 0.3881 - val_loss: 0.0018 - val_accuracy: 0.5158\n",
      "Train on 7740 samples, validate on 832 samples\n",
      "Epoch 1/20\n",
      "7740/7740 [==============================] - 2s 253us/step - loss: 1.0891 - dense_1_loss: 0.0027 - dense_2_loss: 1.0866 - dense_1_accuracy: 0.3694 - dense_2_accuracy: 0.4000 - val_loss: 1.0691 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0547 - val_dense_1_accuracy: 0.4784 - val_dense_2_accuracy: 0.4555\n",
      "Epoch 2/20\n",
      "7740/7740 [==============================] - 2s 199us/step - loss: 1.0768 - dense_1_loss: 0.0027 - dense_2_loss: 1.0740 - dense_1_accuracy: 0.3755 - dense_2_accuracy: 0.4121 - val_loss: 1.0517 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0327 - val_dense_1_accuracy: 0.5108 - val_dense_2_accuracy: 0.4495\n",
      "Epoch 3/20\n",
      "7740/7740 [==============================] - 2s 198us/step - loss: 1.0693 - dense_1_loss: 0.0027 - dense_2_loss: 1.0665 - dense_1_accuracy: 0.3677 - dense_2_accuracy: 0.4262 - val_loss: 1.0463 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0309 - val_dense_1_accuracy: 0.4916 - val_dense_2_accuracy: 0.4471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 1.0608 - dense_1_loss: 0.0027 - dense_2_loss: 1.0585 - dense_1_accuracy: 0.3757 - dense_2_accuracy: 0.4437 - val_loss: 1.0463 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0327 - val_dense_1_accuracy: 0.4712 - val_dense_2_accuracy: 0.4447\n",
      "Epoch 5/20\n",
      "7740/7740 [==============================] - 1s 187us/step - loss: 1.0565 - dense_1_loss: 0.0027 - dense_2_loss: 1.0540 - dense_1_accuracy: 0.3689 - dense_2_accuracy: 0.4519 - val_loss: 1.0439 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0279 - val_dense_1_accuracy: 0.4760 - val_dense_2_accuracy: 0.4471\n",
      "Epoch 6/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 1.0512 - dense_1_loss: 0.0027 - dense_2_loss: 1.0481 - dense_1_accuracy: 0.3762 - dense_2_accuracy: 0.4547 - val_loss: 1.0430 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0236 - val_dense_1_accuracy: 0.4471 - val_dense_2_accuracy: 0.4507\n",
      "Epoch 7/20\n",
      "7740/7740 [==============================] - 1s 192us/step - loss: 1.0475 - dense_1_loss: 0.0027 - dense_2_loss: 1.0445 - dense_1_accuracy: 0.3673 - dense_2_accuracy: 0.4627 - val_loss: 1.0453 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0300 - val_dense_1_accuracy: 0.4507 - val_dense_2_accuracy: 0.4471\n",
      "Epoch 8/20\n",
      "7740/7740 [==============================] - 2s 200us/step - loss: 1.0400 - dense_1_loss: 0.0027 - dense_2_loss: 1.0371 - dense_1_accuracy: 0.3696 - dense_2_accuracy: 0.4689 - val_loss: 1.0466 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0321 - val_dense_1_accuracy: 0.4567 - val_dense_2_accuracy: 0.4399\n",
      "Epoch 9/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 1.0359 - dense_1_loss: 0.0027 - dense_2_loss: 1.0329 - dense_1_accuracy: 0.3603 - dense_2_accuracy: 0.4700 - val_loss: 1.0422 - val_dense_1_loss: 0.0021 - val_dense_2_loss: 1.0269 - val_dense_1_accuracy: 0.4423 - val_dense_2_accuracy: 0.4579\n",
      "Epoch 10/20\n",
      "7740/7740 [==============================] - 2s 199us/step - loss: 1.0290 - dense_1_loss: 0.0027 - dense_2_loss: 1.0261 - dense_1_accuracy: 0.3609 - dense_2_accuracy: 0.4793 - val_loss: 1.0449 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0293 - val_dense_1_accuracy: 0.4435 - val_dense_2_accuracy: 0.4507\n",
      "Epoch 11/20\n",
      "7740/7740 [==============================] - 2s 194us/step - loss: 1.0219 - dense_1_loss: 0.0027 - dense_2_loss: 1.0187 - dense_1_accuracy: 0.3605 - dense_2_accuracy: 0.4872 - val_loss: 1.0455 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0253 - val_dense_1_accuracy: 0.4459 - val_dense_2_accuracy: 0.4423\n",
      "Epoch 12/20\n",
      "7740/7740 [==============================] - 1s 189us/step - loss: 1.0148 - dense_1_loss: 0.0028 - dense_2_loss: 1.0119 - dense_1_accuracy: 0.3614 - dense_2_accuracy: 0.4964 - val_loss: 1.0570 - val_dense_1_loss: 0.0021 - val_dense_2_loss: 1.0458 - val_dense_1_accuracy: 0.4363 - val_dense_2_accuracy: 0.4411\n",
      "Epoch 13/20\n",
      "7740/7740 [==============================] - 1s 187us/step - loss: 1.0049 - dense_1_loss: 0.0028 - dense_2_loss: 1.0026 - dense_1_accuracy: 0.3562 - dense_2_accuracy: 0.5071 - val_loss: 1.0594 - val_dense_1_loss: 0.0021 - val_dense_2_loss: 1.0475 - val_dense_1_accuracy: 0.4303 - val_dense_2_accuracy: 0.4327\n",
      "Epoch 14/20\n",
      "7740/7740 [==============================] - 1s 185us/step - loss: 0.9960 - dense_1_loss: 0.0028 - dense_2_loss: 0.9923 - dense_1_accuracy: 0.3592 - dense_2_accuracy: 0.5096 - val_loss: 1.0545 - val_dense_1_loss: 0.0021 - val_dense_2_loss: 1.0352 - val_dense_1_accuracy: 0.4231 - val_dense_2_accuracy: 0.4375\n",
      "Epoch 15/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.9848 - dense_1_loss: 0.0028 - dense_2_loss: 0.9822 - dense_1_accuracy: 0.3578 - dense_2_accuracy: 0.5211 - val_loss: 1.0642 - val_dense_1_loss: 0.0021 - val_dense_2_loss: 1.0525 - val_dense_1_accuracy: 0.4111 - val_dense_2_accuracy: 0.4399\n",
      "Epoch 16/20\n",
      "7740/7740 [==============================] - 1s 187us/step - loss: 0.9713 - dense_1_loss: 0.0028 - dense_2_loss: 0.9691 - dense_1_accuracy: 0.3470 - dense_2_accuracy: 0.5340 - val_loss: 1.0696 - val_dense_1_loss: 0.0021 - val_dense_2_loss: 1.0587 - val_dense_1_accuracy: 0.4159 - val_dense_2_accuracy: 0.4255\n",
      "Epoch 17/20\n",
      "7740/7740 [==============================] - 2s 199us/step - loss: 0.9568 - dense_1_loss: 0.0028 - dense_2_loss: 0.9538 - dense_1_accuracy: 0.3525 - dense_2_accuracy: 0.5469 - val_loss: 1.0772 - val_dense_1_loss: 0.0022 - val_dense_2_loss: 1.0648 - val_dense_1_accuracy: 0.4207 - val_dense_2_accuracy: 0.4255\n",
      "Epoch 18/20\n",
      "7740/7740 [==============================] - 1s 190us/step - loss: 0.9487 - dense_1_loss: 0.0028 - dense_2_loss: 0.9452 - dense_1_accuracy: 0.3430 - dense_2_accuracy: 0.5509 - val_loss: 1.0751 - val_dense_1_loss: 0.0022 - val_dense_2_loss: 1.0590 - val_dense_1_accuracy: 0.4123 - val_dense_2_accuracy: 0.4459\n",
      "Epoch 19/20\n",
      "7740/7740 [==============================] - 1s 193us/step - loss: 0.9308 - dense_1_loss: 0.0028 - dense_2_loss: 0.9285 - dense_1_accuracy: 0.3460 - dense_2_accuracy: 0.5636 - val_loss: 1.0760 - val_dense_1_loss: 0.0022 - val_dense_2_loss: 1.0538 - val_dense_1_accuracy: 0.4147 - val_dense_2_accuracy: 0.4507\n",
      "Epoch 20/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.9234 - dense_1_loss: 0.0029 - dense_2_loss: 0.9202 - dense_1_accuracy: 0.3430 - dense_2_accuracy: 0.5718 - val_loss: 1.0829 - val_dense_1_loss: 0.0022 - val_dense_2_loss: 1.0655 - val_dense_1_accuracy: 0.4050 - val_dense_2_accuracy: 0.4387\n",
      "Train on 29671 samples, validate on 7419 samples\n",
      "Epoch 1/20\n",
      "29671/29671 [==============================] - 6s 203us/step - loss: 0.0028 - accuracy: 0.3595 - val_loss: 0.0018 - val_accuracy: 0.4966\n",
      "Epoch 2/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0026 - accuracy: 0.3800 - val_loss: 0.0018 - val_accuracy: 0.5095\n",
      "Epoch 3/20\n",
      "29671/29671 [==============================] - 6s 205us/step - loss: 0.0025 - accuracy: 0.3832 - val_loss: 0.0017 - val_accuracy: 0.5114\n",
      "Epoch 4/20\n",
      "29671/29671 [==============================] - 6s 202us/step - loss: 0.0025 - accuracy: 0.3823 - val_loss: 0.0017 - val_accuracy: 0.5192\n",
      "Epoch 5/20\n",
      "29671/29671 [==============================] - 6s 200us/step - loss: 0.0025 - accuracy: 0.3884 - val_loss: 0.0017 - val_accuracy: 0.5219\n",
      "Epoch 6/20\n",
      "29671/29671 [==============================] - 6s 198us/step - loss: 0.0025 - accuracy: 0.3880 - val_loss: 0.0017 - val_accuracy: 0.5226\n",
      "Epoch 7/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0025 - accuracy: 0.3897 - val_loss: 0.0017 - val_accuracy: 0.5237\n",
      "Epoch 8/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0025 - accuracy: 0.3918 - val_loss: 0.0017 - val_accuracy: 0.5247\n",
      "Epoch 9/20\n",
      "29671/29671 [==============================] - 6s 209us/step - loss: 0.0025 - accuracy: 0.3994 - val_loss: 0.0017 - val_accuracy: 0.5242\n",
      "Epoch 10/20\n",
      "29671/29671 [==============================] - 6s 203us/step - loss: 0.0025 - accuracy: 0.3947 - val_loss: 0.0017 - val_accuracy: 0.5288\n",
      "Epoch 11/20\n",
      "29671/29671 [==============================] - 6s 215us/step - loss: 0.0025 - accuracy: 0.3926 - val_loss: 0.0017 - val_accuracy: 0.5211\n",
      "Epoch 12/20\n",
      "29671/29671 [==============================] - 6s 209us/step - loss: 0.0025 - accuracy: 0.3954 - val_loss: 0.0017 - val_accuracy: 0.5204\n",
      "Epoch 13/20\n",
      "29671/29671 [==============================] - 6s 202us/step - loss: 0.0025 - accuracy: 0.3985 - val_loss: 0.0017 - val_accuracy: 0.5320\n",
      "Epoch 14/20\n",
      "29671/29671 [==============================] - 6s 203us/step - loss: 0.0025 - accuracy: 0.3936 - val_loss: 0.0017 - val_accuracy: 0.5253\n",
      "Epoch 15/20\n",
      "29671/29671 [==============================] - 6s 202us/step - loss: 0.0025 - accuracy: 0.3945 - val_loss: 0.0017 - val_accuracy: 0.5332\n",
      "Epoch 16/20\n",
      "29671/29671 [==============================] - 6s 202us/step - loss: 0.0025 - accuracy: 0.4000 - val_loss: 0.0017 - val_accuracy: 0.5250\n",
      "Epoch 17/20\n",
      "29671/29671 [==============================] - 6s 207us/step - loss: 0.0025 - accuracy: 0.3977 - val_loss: 0.0016 - val_accuracy: 0.5304\n",
      "Epoch 18/20\n",
      "29671/29671 [==============================] - 6s 198us/step - loss: 0.0025 - accuracy: 0.3969 - val_loss: 0.0017 - val_accuracy: 0.5297\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29671/29671 [==============================] - 6s 200us/step - loss: 0.0025 - accuracy: 0.3951 - val_loss: 0.0017 - val_accuracy: 0.5202\n",
      "Epoch 20/20\n",
      "29671/29671 [==============================] - 6s 200us/step - loss: 0.0025 - accuracy: 0.4002 - val_loss: 0.0017 - val_accuracy: 0.5297\n",
      "Train on 7740 samples, validate on 832 samples\n",
      "Epoch 1/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 1.0870 - dense_1_loss: 0.0026 - dense_2_loss: 1.0845 - dense_1_accuracy: 0.3857 - dense_2_accuracy: 0.4300 - val_loss: 1.0614 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0497 - val_dense_1_accuracy: 0.4627 - val_dense_2_accuracy: 0.4567\n",
      "Epoch 2/20\n",
      "7740/7740 [==============================] - 1s 193us/step - loss: 1.0416 - dense_1_loss: 0.0025 - dense_2_loss: 1.0392 - dense_1_accuracy: 0.3885 - dense_2_accuracy: 0.4602 - val_loss: 1.0475 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0344 - val_dense_1_accuracy: 0.4820 - val_dense_2_accuracy: 0.4627\n",
      "Epoch 3/20\n",
      "7740/7740 [==============================] - 1s 192us/step - loss: 1.0241 - dense_1_loss: 0.0025 - dense_2_loss: 1.0217 - dense_1_accuracy: 0.4000 - dense_2_accuracy: 0.4823 - val_loss: 1.0483 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0308 - val_dense_1_accuracy: 0.4639 - val_dense_2_accuracy: 0.4724\n",
      "Epoch 4/20\n",
      "7740/7740 [==============================] - 1s 186us/step - loss: 1.0130 - dense_1_loss: 0.0025 - dense_2_loss: 1.0104 - dense_1_accuracy: 0.3860 - dense_2_accuracy: 0.4885 - val_loss: 1.0528 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0408 - val_dense_1_accuracy: 0.4844 - val_dense_2_accuracy: 0.4627\n",
      "Epoch 5/20\n",
      "7740/7740 [==============================] - 1s 193us/step - loss: 0.9973 - dense_1_loss: 0.0025 - dense_2_loss: 0.9948 - dense_1_accuracy: 0.3930 - dense_2_accuracy: 0.5106 - val_loss: 1.0470 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0231 - val_dense_1_accuracy: 0.4712 - val_dense_2_accuracy: 0.4639\n",
      "Epoch 6/20\n",
      "7740/7740 [==============================] - 1s 187us/step - loss: 0.9842 - dense_1_loss: 0.0025 - dense_2_loss: 0.9819 - dense_1_accuracy: 0.3837 - dense_2_accuracy: 0.5191 - val_loss: 1.0827 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0766 - val_dense_1_accuracy: 0.4615 - val_dense_2_accuracy: 0.4050\n",
      "Epoch 7/20\n",
      "7740/7740 [==============================] - 1s 187us/step - loss: 0.9716 - dense_1_loss: 0.0025 - dense_2_loss: 0.9688 - dense_1_accuracy: 0.3837 - dense_2_accuracy: 0.5328 - val_loss: 1.0594 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0405 - val_dense_1_accuracy: 0.4736 - val_dense_2_accuracy: 0.4435\n",
      "Epoch 8/20\n",
      "7740/7740 [==============================] - 2s 200us/step - loss: 0.9575 - dense_1_loss: 0.0025 - dense_2_loss: 0.9551 - dense_1_accuracy: 0.3809 - dense_2_accuracy: 0.5443 - val_loss: 1.0673 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0575 - val_dense_1_accuracy: 0.4651 - val_dense_2_accuracy: 0.4219\n",
      "Epoch 9/20\n",
      "7740/7740 [==============================] - 2s 214us/step - loss: 0.9437 - dense_1_loss: 0.0025 - dense_2_loss: 0.9406 - dense_1_accuracy: 0.3820 - dense_2_accuracy: 0.5592 - val_loss: 1.0664 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0514 - val_dense_1_accuracy: 0.4447 - val_dense_2_accuracy: 0.4279\n",
      "Epoch 10/20\n",
      "7740/7740 [==============================] - 2s 212us/step - loss: 0.9274 - dense_1_loss: 0.0026 - dense_2_loss: 0.9251 - dense_1_accuracy: 0.3819 - dense_2_accuracy: 0.5713 - val_loss: 1.0761 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0541 - val_dense_1_accuracy: 0.4435 - val_dense_2_accuracy: 0.4447\n",
      "Epoch 11/20\n",
      "7740/7740 [==============================] - 2s 209us/step - loss: 0.9177 - dense_1_loss: 0.0026 - dense_2_loss: 0.9157 - dense_1_accuracy: 0.3776 - dense_2_accuracy: 0.5743 - val_loss: 1.0776 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0570 - val_dense_1_accuracy: 0.4543 - val_dense_2_accuracy: 0.4351\n",
      "Epoch 12/20\n",
      "7740/7740 [==============================] - 2s 207us/step - loss: 0.9030 - dense_1_loss: 0.0026 - dense_2_loss: 0.9008 - dense_1_accuracy: 0.3743 - dense_2_accuracy: 0.5876 - val_loss: 1.0833 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0566 - val_dense_1_accuracy: 0.4435 - val_dense_2_accuracy: 0.4531\n",
      "Epoch 13/20\n",
      "7740/7740 [==============================] - 2s 208us/step - loss: 0.8927 - dense_1_loss: 0.0026 - dense_2_loss: 0.8898 - dense_1_accuracy: 0.3819 - dense_2_accuracy: 0.5893 - val_loss: 1.0955 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0765 - val_dense_1_accuracy: 0.4507 - val_dense_2_accuracy: 0.4447\n",
      "Epoch 14/20\n",
      "7740/7740 [==============================] - 1s 190us/step - loss: 0.8777 - dense_1_loss: 0.0026 - dense_2_loss: 0.8756 - dense_1_accuracy: 0.3705 - dense_2_accuracy: 0.5984 - val_loss: 1.1085 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0958 - val_dense_1_accuracy: 0.4471 - val_dense_2_accuracy: 0.4123\n",
      "Epoch 15/20\n",
      "7740/7740 [==============================] - 1s 189us/step - loss: 0.8591 - dense_1_loss: 0.0026 - dense_2_loss: 0.8571 - dense_1_accuracy: 0.3779 - dense_2_accuracy: 0.6130 - val_loss: 1.1085 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.0850 - val_dense_1_accuracy: 0.4399 - val_dense_2_accuracy: 0.4231\n",
      "Epoch 16/20\n",
      "7740/7740 [==============================] - 1s 187us/step - loss: 0.8461 - dense_1_loss: 0.0026 - dense_2_loss: 0.8435 - dense_1_accuracy: 0.3736 - dense_2_accuracy: 0.6248 - val_loss: 1.1239 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.1000 - val_dense_1_accuracy: 0.4459 - val_dense_2_accuracy: 0.4363\n",
      "Epoch 17/20\n",
      "7740/7740 [==============================] - 1s 190us/step - loss: 0.8316 - dense_1_loss: 0.0026 - dense_2_loss: 0.8288 - dense_1_accuracy: 0.3714 - dense_2_accuracy: 0.6284 - val_loss: 1.1586 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.1484 - val_dense_1_accuracy: 0.4507 - val_dense_2_accuracy: 0.4123\n",
      "Epoch 18/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.8176 - dense_1_loss: 0.0027 - dense_2_loss: 0.8149 - dense_1_accuracy: 0.3687 - dense_2_accuracy: 0.6422 - val_loss: 1.1542 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.1380 - val_dense_1_accuracy: 0.4495 - val_dense_2_accuracy: 0.4135\n",
      "Epoch 19/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.8033 - dense_1_loss: 0.0027 - dense_2_loss: 0.7999 - dense_1_accuracy: 0.3606 - dense_2_accuracy: 0.6468 - val_loss: 1.2047 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.2056 - val_dense_1_accuracy: 0.4435 - val_dense_2_accuracy: 0.3930\n",
      "Epoch 20/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 0.7893 - dense_1_loss: 0.0027 - dense_2_loss: 0.7854 - dense_1_accuracy: 0.3665 - dense_2_accuracy: 0.6572 - val_loss: 1.1977 - val_dense_1_loss: 0.0020 - val_dense_2_loss: 1.1835 - val_dense_1_accuracy: 0.4255 - val_dense_2_accuracy: 0.4159\n",
      "Train on 29671 samples, validate on 7419 samples\n",
      "Epoch 1/20\n",
      "29671/29671 [==============================] - 6s 199us/step - loss: 0.0026 - accuracy: 0.3804 - val_loss: 0.0017 - val_accuracy: 0.5200\n",
      "Epoch 2/20\n",
      "29671/29671 [==============================] - 6s 200us/step - loss: 0.0025 - accuracy: 0.3923 - val_loss: 0.0017 - val_accuracy: 0.5247\n",
      "Epoch 3/20\n",
      "29671/29671 [==============================] - 6s 198us/step - loss: 0.0025 - accuracy: 0.3946 - val_loss: 0.0017 - val_accuracy: 0.5196\n",
      "Epoch 4/20\n",
      "29671/29671 [==============================] - 6s 198us/step - loss: 0.0025 - accuracy: 0.3927 - val_loss: 0.0016 - val_accuracy: 0.5261\n",
      "Epoch 5/20\n",
      "29671/29671 [==============================] - 6s 199us/step - loss: 0.0025 - accuracy: 0.3953 - val_loss: 0.0016 - val_accuracy: 0.5309\n",
      "Epoch 6/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0025 - accuracy: 0.3989 - val_loss: 0.0016 - val_accuracy: 0.5265\n",
      "Epoch 7/20\n",
      "29671/29671 [==============================] - 6s 201us/step - loss: 0.0025 - accuracy: 0.3962 - val_loss: 0.0016 - val_accuracy: 0.5330\n",
      "Epoch 8/20\n",
      "29671/29671 [==============================] - 6s 202us/step - loss: 0.0024 - accuracy: 0.3987 - val_loss: 0.0016 - val_accuracy: 0.5257\n",
      "Epoch 9/20\n",
      "29671/29671 [==============================] - 6s 200us/step - loss: 0.0024 - accuracy: 0.3940 - val_loss: 0.0016 - val_accuracy: 0.5295\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29671/29671 [==============================] - 6s 199us/step - loss: 0.0024 - accuracy: 0.3985 - val_loss: 0.0016 - val_accuracy: 0.5299\n",
      "Epoch 11/20\n",
      "29671/29671 [==============================] - 6s 199us/step - loss: 0.0024 - accuracy: 0.3940 - val_loss: 0.0016 - val_accuracy: 0.5307\n",
      "Epoch 12/20\n",
      "29671/29671 [==============================] - 6s 197us/step - loss: 0.0024 - accuracy: 0.4007 - val_loss: 0.0016 - val_accuracy: 0.5359\n",
      "Epoch 13/20\n",
      "29671/29671 [==============================] - 6s 201us/step - loss: 0.0024 - accuracy: 0.3973 - val_loss: 0.0016 - val_accuracy: 0.5282\n",
      "Epoch 14/20\n",
      "29671/29671 [==============================] - 6s 199us/step - loss: 0.0024 - accuracy: 0.3967 - val_loss: 0.0016 - val_accuracy: 0.5297\n",
      "Epoch 15/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0024 - accuracy: 0.4006 - val_loss: 0.0016 - val_accuracy: 0.5338\n",
      "Epoch 16/20\n",
      "29671/29671 [==============================] - 6s 200us/step - loss: 0.0024 - accuracy: 0.4009 - val_loss: 0.0016 - val_accuracy: 0.5340\n",
      "Epoch 17/20\n",
      "29671/29671 [==============================] - 6s 202us/step - loss: 0.0024 - accuracy: 0.4007 - val_loss: 0.0016 - val_accuracy: 0.5323\n",
      "Epoch 18/20\n",
      "29671/29671 [==============================] - 6s 199us/step - loss: 0.0024 - accuracy: 0.3968 - val_loss: 0.0016 - val_accuracy: 0.5354\n",
      "Epoch 19/20\n",
      "29671/29671 [==============================] - 6s 201us/step - loss: 0.0024 - accuracy: 0.4002 - val_loss: 0.0016 - val_accuracy: 0.5320\n",
      "Epoch 20/20\n",
      "29671/29671 [==============================] - 6s 202us/step - loss: 0.0024 - accuracy: 0.4021 - val_loss: 0.0016 - val_accuracy: 0.5355\n",
      "Train on 7740 samples, validate on 832 samples\n",
      "Epoch 1/20\n",
      "7740/7740 [==============================] - 2s 195us/step - loss: 1.1112 - dense_1_loss: 0.0025 - dense_2_loss: 1.1089 - dense_1_accuracy: 0.3813 - dense_2_accuracy: 0.4359 - val_loss: 1.0554 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0382 - val_dense_1_accuracy: 0.4627 - val_dense_2_accuracy: 0.4603\n",
      "Epoch 2/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 1.0300 - dense_1_loss: 0.0025 - dense_2_loss: 1.0274 - dense_1_accuracy: 0.3906 - dense_2_accuracy: 0.4814 - val_loss: 1.0616 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0466 - val_dense_1_accuracy: 0.4688 - val_dense_2_accuracy: 0.4399\n",
      "Epoch 3/20\n",
      "7740/7740 [==============================] - 2s 194us/step - loss: 1.0111 - dense_1_loss: 0.0025 - dense_2_loss: 1.0087 - dense_1_accuracy: 0.3966 - dense_2_accuracy: 0.4894 - val_loss: 1.0630 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0499 - val_dense_1_accuracy: 0.4808 - val_dense_2_accuracy: 0.4399\n",
      "Epoch 4/20\n",
      "7740/7740 [==============================] - 2s 198us/step - loss: 0.9936 - dense_1_loss: 0.0024 - dense_2_loss: 0.9913 - dense_1_accuracy: 0.3903 - dense_2_accuracy: 0.5044 - val_loss: 1.0676 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0524 - val_dense_1_accuracy: 0.4688 - val_dense_2_accuracy: 0.4423\n",
      "Epoch 5/20\n",
      "7740/7740 [==============================] - 2s 201us/step - loss: 0.9756 - dense_1_loss: 0.0025 - dense_2_loss: 0.9740 - dense_1_accuracy: 0.3866 - dense_2_accuracy: 0.5251 - val_loss: 1.0637 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0483 - val_dense_1_accuracy: 0.4748 - val_dense_2_accuracy: 0.4351\n",
      "Epoch 6/20\n",
      "7740/7740 [==============================] - 2s 202us/step - loss: 0.9620 - dense_1_loss: 0.0025 - dense_2_loss: 0.9596 - dense_1_accuracy: 0.3925 - dense_2_accuracy: 0.5337 - val_loss: 1.0920 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0860 - val_dense_1_accuracy: 0.4976 - val_dense_2_accuracy: 0.4159\n",
      "Epoch 7/20\n",
      "7740/7740 [==============================] - 2s 194us/step - loss: 0.9364 - dense_1_loss: 0.0025 - dense_2_loss: 0.9333 - dense_1_accuracy: 0.3947 - dense_2_accuracy: 0.5541 - val_loss: 1.1249 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1256 - val_dense_1_accuracy: 0.4880 - val_dense_2_accuracy: 0.4135\n",
      "Epoch 8/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.9287 - dense_1_loss: 0.0025 - dense_2_loss: 0.9261 - dense_1_accuracy: 0.3930 - dense_2_accuracy: 0.5534 - val_loss: 1.1005 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0939 - val_dense_1_accuracy: 0.4808 - val_dense_2_accuracy: 0.4219\n",
      "Epoch 9/20\n",
      "7740/7740 [==============================] - 2s 194us/step - loss: 0.9030 - dense_1_loss: 0.0025 - dense_2_loss: 0.9006 - dense_1_accuracy: 0.3845 - dense_2_accuracy: 0.5766 - val_loss: 1.1138 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1045 - val_dense_1_accuracy: 0.4700 - val_dense_2_accuracy: 0.4159\n",
      "Epoch 10/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.8919 - dense_1_loss: 0.0025 - dense_2_loss: 0.8904 - dense_1_accuracy: 0.3932 - dense_2_accuracy: 0.5919 - val_loss: 1.1250 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1150 - val_dense_1_accuracy: 0.4663 - val_dense_2_accuracy: 0.4279\n",
      "Epoch 11/20\n",
      "7740/7740 [==============================] - 1s 192us/step - loss: 0.8803 - dense_1_loss: 0.0025 - dense_2_loss: 0.8780 - dense_1_accuracy: 0.3932 - dense_2_accuracy: 0.5907 - val_loss: 1.1151 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.0926 - val_dense_1_accuracy: 0.4519 - val_dense_2_accuracy: 0.4399\n",
      "Epoch 12/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 0.8641 - dense_1_loss: 0.0025 - dense_2_loss: 0.8623 - dense_1_accuracy: 0.3807 - dense_2_accuracy: 0.6050 - val_loss: 1.1399 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.1247 - val_dense_1_accuracy: 0.4447 - val_dense_2_accuracy: 0.4231\n",
      "Epoch 13/20\n",
      "7740/7740 [==============================] - 1s 192us/step - loss: 0.8439 - dense_1_loss: 0.0025 - dense_2_loss: 0.8423 - dense_1_accuracy: 0.3749 - dense_2_accuracy: 0.6218 - val_loss: 1.1481 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.1300 - val_dense_1_accuracy: 0.4459 - val_dense_2_accuracy: 0.4291\n",
      "Epoch 14/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.8331 - dense_1_loss: 0.0026 - dense_2_loss: 0.8308 - dense_1_accuracy: 0.3811 - dense_2_accuracy: 0.6284 - val_loss: 1.1393 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.1185 - val_dense_1_accuracy: 0.4567 - val_dense_2_accuracy: 0.4315\n",
      "Epoch 15/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 0.8170 - dense_1_loss: 0.0026 - dense_2_loss: 0.8144 - dense_1_accuracy: 0.3829 - dense_2_accuracy: 0.6402 - val_loss: 1.1811 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.1634 - val_dense_1_accuracy: 0.4411 - val_dense_2_accuracy: 0.4219\n",
      "Epoch 16/20\n",
      "7740/7740 [==============================] - 1s 194us/step - loss: 0.8001 - dense_1_loss: 0.0026 - dense_2_loss: 0.7980 - dense_1_accuracy: 0.3739 - dense_2_accuracy: 0.6484 - val_loss: 1.1893 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.1807 - val_dense_1_accuracy: 0.4327 - val_dense_2_accuracy: 0.4075\n",
      "Epoch 17/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.7887 - dense_1_loss: 0.0026 - dense_2_loss: 0.7855 - dense_1_accuracy: 0.3760 - dense_2_accuracy: 0.6526 - val_loss: 1.1811 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.1702 - val_dense_1_accuracy: 0.4483 - val_dense_2_accuracy: 0.4123\n",
      "Epoch 18/20\n",
      "7740/7740 [==============================] - 1s 192us/step - loss: 0.7787 - dense_1_loss: 0.0026 - dense_2_loss: 0.7759 - dense_1_accuracy: 0.3669 - dense_2_accuracy: 0.6583 - val_loss: 1.1984 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.1734 - val_dense_1_accuracy: 0.4399 - val_dense_2_accuracy: 0.4243\n",
      "Epoch 19/20\n",
      "7740/7740 [==============================] - 2s 194us/step - loss: 0.7618 - dense_1_loss: 0.0026 - dense_2_loss: 0.7594 - dense_1_accuracy: 0.3805 - dense_2_accuracy: 0.6647 - val_loss: 1.2401 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.2301 - val_dense_1_accuracy: 0.4399 - val_dense_2_accuracy: 0.4014\n",
      "Epoch 20/20\n",
      "7740/7740 [==============================] - 2s 207us/step - loss: 0.7478 - dense_1_loss: 0.0026 - dense_2_loss: 0.7457 - dense_1_accuracy: 0.3726 - dense_2_accuracy: 0.6764 - val_loss: 1.2394 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.2321 - val_dense_1_accuracy: 0.4399 - val_dense_2_accuracy: 0.3870\n",
      "Train on 29671 samples, validate on 7419 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29671/29671 [==============================] - 6s 218us/step - loss: 0.0026 - accuracy: 0.3855 - val_loss: 0.0016 - val_accuracy: 0.5251\n",
      "Epoch 2/20\n",
      "29671/29671 [==============================] - 7s 223us/step - loss: 0.0025 - accuracy: 0.3992 - val_loss: 0.0016 - val_accuracy: 0.5282\n",
      "Epoch 3/20\n",
      "29671/29671 [==============================] - 7s 226us/step - loss: 0.0024 - accuracy: 0.3980 - val_loss: 0.0016 - val_accuracy: 0.5268\n",
      "Epoch 4/20\n",
      "29671/29671 [==============================] - 8s 266us/step - loss: 0.0024 - accuracy: 0.4014 - val_loss: 0.0016 - val_accuracy: 0.5303\n",
      "Epoch 5/20\n",
      "29671/29671 [==============================] - 7s 242us/step - loss: 0.0024 - accuracy: 0.3960 - val_loss: 0.0016 - val_accuracy: 0.5326\n",
      "Epoch 6/20\n",
      "29671/29671 [==============================] - 6s 215us/step - loss: 0.0024 - accuracy: 0.4004 - val_loss: 0.0016 - val_accuracy: 0.5321\n",
      "Epoch 7/20\n",
      "29671/29671 [==============================] - 6s 218us/step - loss: 0.0024 - accuracy: 0.3998 - val_loss: 0.0016 - val_accuracy: 0.5276\n",
      "Epoch 8/20\n",
      "29671/29671 [==============================] - 7s 222us/step - loss: 0.0024 - accuracy: 0.3989 - val_loss: 0.0016 - val_accuracy: 0.5301\n",
      "Epoch 9/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0024 - accuracy: 0.3963 - val_loss: 0.0016 - val_accuracy: 0.5328\n",
      "Epoch 10/20\n",
      "29671/29671 [==============================] - 7s 225us/step - loss: 0.0024 - accuracy: 0.4001 - val_loss: 0.0016 - val_accuracy: 0.5344\n",
      "Epoch 11/20\n",
      "29671/29671 [==============================] - 7s 223us/step - loss: 0.0024 - accuracy: 0.4003 - val_loss: 0.0016 - val_accuracy: 0.5317\n",
      "Epoch 12/20\n",
      "29671/29671 [==============================] - 7s 236us/step - loss: 0.0024 - accuracy: 0.3989 - val_loss: 0.0016 - val_accuracy: 0.5338\n",
      "Epoch 13/20\n",
      "29671/29671 [==============================] - 7s 233us/step - loss: 0.0024 - accuracy: 0.4015 - val_loss: 0.0016 - val_accuracy: 0.5249\n",
      "Epoch 14/20\n",
      "29671/29671 [==============================] - 6s 217us/step - loss: 0.0024 - accuracy: 0.4004 - val_loss: 0.0016 - val_accuracy: 0.5348\n",
      "Epoch 15/20\n",
      "29671/29671 [==============================] - 7s 245us/step - loss: 0.0024 - accuracy: 0.3989 - val_loss: 0.0016 - val_accuracy: 0.5331\n",
      "Epoch 16/20\n",
      "29671/29671 [==============================] - 8s 257us/step - loss: 0.0024 - accuracy: 0.4012 - val_loss: 0.0016 - val_accuracy: 0.5330\n",
      "Epoch 17/20\n",
      "29671/29671 [==============================] - 7s 225us/step - loss: 0.0024 - accuracy: 0.4037 - val_loss: 0.0016 - val_accuracy: 0.5304\n",
      "Epoch 18/20\n",
      "29671/29671 [==============================] - 7s 236us/step - loss: 0.0024 - accuracy: 0.4013 - val_loss: 0.0016 - val_accuracy: 0.5367\n",
      "Epoch 19/20\n",
      "29671/29671 [==============================] - 7s 228us/step - loss: 0.0024 - accuracy: 0.4022 - val_loss: 0.0016 - val_accuracy: 0.5315\n",
      "Epoch 20/20\n",
      "29671/29671 [==============================] - 6s 212us/step - loss: 0.0024 - accuracy: 0.3985 - val_loss: 0.0016 - val_accuracy: 0.5309\n",
      "Train on 7740 samples, validate on 832 samples\n",
      "Epoch 1/20\n",
      "7740/7740 [==============================] - 2s 210us/step - loss: 1.1075 - dense_1_loss: 0.0025 - dense_2_loss: 1.1053 - dense_1_accuracy: 0.3991 - dense_2_accuracy: 0.4341 - val_loss: 1.0609 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0476 - val_dense_1_accuracy: 0.4832 - val_dense_2_accuracy: 0.4423\n",
      "Epoch 2/20\n",
      "7740/7740 [==============================] - 2s 210us/step - loss: 1.0256 - dense_1_loss: 0.0024 - dense_2_loss: 1.0230 - dense_1_accuracy: 0.3984 - dense_2_accuracy: 0.4796 - val_loss: 1.0666 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0575 - val_dense_1_accuracy: 0.4916 - val_dense_2_accuracy: 0.4387\n",
      "Epoch 3/20\n",
      "7740/7740 [==============================] - 2s 208us/step - loss: 1.0047 - dense_1_loss: 0.0024 - dense_2_loss: 1.0029 - dense_1_accuracy: 0.3960 - dense_2_accuracy: 0.4952 - val_loss: 1.0784 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0708 - val_dense_1_accuracy: 0.4808 - val_dense_2_accuracy: 0.4351\n",
      "Epoch 4/20\n",
      "7740/7740 [==============================] - 2s 197us/step - loss: 0.9838 - dense_1_loss: 0.0024 - dense_2_loss: 0.9814 - dense_1_accuracy: 0.4023 - dense_2_accuracy: 0.5143 - val_loss: 1.0693 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0536 - val_dense_1_accuracy: 0.4988 - val_dense_2_accuracy: 0.4507\n",
      "Epoch 5/20\n",
      "7740/7740 [==============================] - 2s 206us/step - loss: 0.9643 - dense_1_loss: 0.0024 - dense_2_loss: 0.9623 - dense_1_accuracy: 0.4049 - dense_2_accuracy: 0.5313 - val_loss: 1.0709 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0477 - val_dense_1_accuracy: 0.4700 - val_dense_2_accuracy: 0.4579\n",
      "Epoch 6/20\n",
      "7740/7740 [==============================] - 2s 220us/step - loss: 0.9444 - dense_1_loss: 0.0024 - dense_2_loss: 0.9421 - dense_1_accuracy: 0.3929 - dense_2_accuracy: 0.5481 - val_loss: 1.0992 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0940 - val_dense_1_accuracy: 0.4820 - val_dense_2_accuracy: 0.4255\n",
      "Epoch 7/20\n",
      "7740/7740 [==============================] - 2s 224us/step - loss: 0.9358 - dense_1_loss: 0.0024 - dense_2_loss: 0.9337 - dense_1_accuracy: 0.3891 - dense_2_accuracy: 0.5532 - val_loss: 1.0877 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0596 - val_dense_1_accuracy: 0.4688 - val_dense_2_accuracy: 0.4459\n",
      "Epoch 8/20\n",
      "7740/7740 [==============================] - 2s 239us/step - loss: 0.9075 - dense_1_loss: 0.0024 - dense_2_loss: 0.9056 - dense_1_accuracy: 0.4009 - dense_2_accuracy: 0.5704 - val_loss: 1.1109 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0989 - val_dense_1_accuracy: 0.4928 - val_dense_2_accuracy: 0.4447\n",
      "Epoch 9/20\n",
      "7740/7740 [==============================] - 2s 276us/step - loss: 0.8883 - dense_1_loss: 0.0024 - dense_2_loss: 0.8861 - dense_1_accuracy: 0.3951 - dense_2_accuracy: 0.5871 - val_loss: 1.1079 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0953 - val_dense_1_accuracy: 0.4892 - val_dense_2_accuracy: 0.4339\n",
      "Epoch 10/20\n",
      "7740/7740 [==============================] - 2s 267us/step - loss: 0.8724 - dense_1_loss: 0.0025 - dense_2_loss: 0.8703 - dense_1_accuracy: 0.3907 - dense_2_accuracy: 0.6025 - val_loss: 1.1458 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1416 - val_dense_1_accuracy: 0.4591 - val_dense_2_accuracy: 0.4423\n",
      "Epoch 11/20\n",
      "7740/7740 [==============================] - 2s 238us/step - loss: 0.8590 - dense_1_loss: 0.0025 - dense_2_loss: 0.8562 - dense_1_accuracy: 0.3868 - dense_2_accuracy: 0.6088 - val_loss: 1.1622 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1597 - val_dense_1_accuracy: 0.4591 - val_dense_2_accuracy: 0.4014\n",
      "Epoch 12/20\n",
      "7740/7740 [==============================] - 2s 281us/step - loss: 0.8385 - dense_1_loss: 0.0025 - dense_2_loss: 0.8348 - dense_1_accuracy: 0.3867 - dense_2_accuracy: 0.6227 - val_loss: 1.1633 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1385 - val_dense_1_accuracy: 0.4736 - val_dense_2_accuracy: 0.4159\n",
      "Epoch 13/20\n",
      "7740/7740 [==============================] - 2s 202us/step - loss: 0.8267 - dense_1_loss: 0.0025 - dense_2_loss: 0.8238 - dense_1_accuracy: 0.3854 - dense_2_accuracy: 0.6244 - val_loss: 1.1579 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1403 - val_dense_1_accuracy: 0.4627 - val_dense_2_accuracy: 0.4147\n",
      "Epoch 14/20\n",
      "7740/7740 [==============================] - 2s 199us/step - loss: 0.8111 - dense_1_loss: 0.0025 - dense_2_loss: 0.8083 - dense_1_accuracy: 0.3840 - dense_2_accuracy: 0.6398 - val_loss: 1.1931 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1885 - val_dense_1_accuracy: 0.4651 - val_dense_2_accuracy: 0.4147\n",
      "Epoch 15/20\n",
      "7740/7740 [==============================] - 2s 244us/step - loss: 0.7946 - dense_1_loss: 0.0025 - dense_2_loss: 0.7927 - dense_1_accuracy: 0.3844 - dense_2_accuracy: 0.6451 - val_loss: 1.2040 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1865 - val_dense_1_accuracy: 0.4411 - val_dense_2_accuracy: 0.4207\n",
      "Epoch 16/20\n",
      "7740/7740 [==============================] - 2s 274us/step - loss: 0.7779 - dense_1_loss: 0.0025 - dense_2_loss: 0.7753 - dense_1_accuracy: 0.3851 - dense_2_accuracy: 0.6557 - val_loss: 1.2079 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1994 - val_dense_1_accuracy: 0.4507 - val_dense_2_accuracy: 0.4159\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 2s 221us/step - loss: 0.7734 - dense_1_loss: 0.0025 - dense_2_loss: 0.7711 - dense_1_accuracy: 0.3764 - dense_2_accuracy: 0.6553 - val_loss: 1.2030 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.1749 - val_dense_1_accuracy: 0.4471 - val_dense_2_accuracy: 0.4243\n",
      "Epoch 18/20\n",
      "7740/7740 [==============================] - 2s 206us/step - loss: 0.7663 - dense_1_loss: 0.0025 - dense_2_loss: 0.7637 - dense_1_accuracy: 0.3801 - dense_2_accuracy: 0.6567 - val_loss: 1.2190 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.2007 - val_dense_1_accuracy: 0.4555 - val_dense_2_accuracy: 0.4183\n",
      "Epoch 19/20\n",
      "7740/7740 [==============================] - 2s 216us/step - loss: 0.7453 - dense_1_loss: 0.0025 - dense_2_loss: 0.7433 - dense_1_accuracy: 0.3748 - dense_2_accuracy: 0.6778 - val_loss: 1.2339 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.2034 - val_dense_1_accuracy: 0.4423 - val_dense_2_accuracy: 0.4195\n",
      "Epoch 20/20\n",
      "7740/7740 [==============================] - 2s 220us/step - loss: 0.7384 - dense_1_loss: 0.0025 - dense_2_loss: 0.7358 - dense_1_accuracy: 0.3793 - dense_2_accuracy: 0.6806 - val_loss: 1.2451 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.2329 - val_dense_1_accuracy: 0.4435 - val_dense_2_accuracy: 0.3978\n",
      "Train on 29671 samples, validate on 7419 samples\n",
      "Epoch 1/20\n",
      "29671/29671 [==============================] - 7s 237us/step - loss: 0.0026 - accuracy: 0.3857 - val_loss: 0.0016 - val_accuracy: 0.5237\n",
      "Epoch 2/20\n",
      "29671/29671 [==============================] - 7s 230us/step - loss: 0.0024 - accuracy: 0.4000 - val_loss: 0.0016 - val_accuracy: 0.5249\n",
      "Epoch 3/20\n",
      "29671/29671 [==============================] - 7s 231us/step - loss: 0.0024 - accuracy: 0.3986 - val_loss: 0.0016 - val_accuracy: 0.5253\n",
      "Epoch 4/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0024 - accuracy: 0.3983 - val_loss: 0.0016 - val_accuracy: 0.5288\n",
      "Epoch 5/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0024 - accuracy: 0.4019 - val_loss: 0.0016 - val_accuracy: 0.5223\n",
      "Epoch 6/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0024 - accuracy: 0.4001 - val_loss: 0.0016 - val_accuracy: 0.5301\n",
      "Epoch 7/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0024 - accuracy: 0.3971 - val_loss: 0.0016 - val_accuracy: 0.5274\n",
      "Epoch 8/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0024 - accuracy: 0.4031 - val_loss: 0.0016 - val_accuracy: 0.5265\n",
      "Epoch 9/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0024 - accuracy: 0.4000 - val_loss: 0.0016 - val_accuracy: 0.5321\n",
      "Epoch 10/20\n",
      "29671/29671 [==============================] - 6s 205us/step - loss: 0.0024 - accuracy: 0.3996 - val_loss: 0.0016 - val_accuracy: 0.5266\n",
      "Epoch 11/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0024 - accuracy: 0.3994 - val_loss: 0.0016 - val_accuracy: 0.5309\n",
      "Epoch 12/20\n",
      "29671/29671 [==============================] - 6s 205us/step - loss: 0.0024 - accuracy: 0.4028 - val_loss: 0.0016 - val_accuracy: 0.5247\n",
      "Epoch 13/20\n",
      "29671/29671 [==============================] - 6s 207us/step - loss: 0.0024 - accuracy: 0.3971 - val_loss: 0.0016 - val_accuracy: 0.5268\n",
      "Epoch 14/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0024 - accuracy: 0.3995 - val_loss: 0.0016 - val_accuracy: 0.5224\n",
      "Epoch 15/20\n",
      "29671/29671 [==============================] - 6s 205us/step - loss: 0.0024 - accuracy: 0.3986 - val_loss: 0.0016 - val_accuracy: 0.5261\n",
      "Epoch 16/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0024 - accuracy: 0.4020 - val_loss: 0.0016 - val_accuracy: 0.5253\n",
      "Epoch 17/20\n",
      "29671/29671 [==============================] - 6s 206us/step - loss: 0.0024 - accuracy: 0.4020 - val_loss: 0.0016 - val_accuracy: 0.5311\n",
      "Epoch 18/20\n",
      "29671/29671 [==============================] - 6s 204us/step - loss: 0.0024 - accuracy: 0.3991 - val_loss: 0.0016 - val_accuracy: 0.5257\n",
      "Epoch 19/20\n",
      "29671/29671 [==============================] - 6s 203us/step - loss: 0.0024 - accuracy: 0.3963 - val_loss: 0.0016 - val_accuracy: 0.5180\n",
      "Epoch 20/20\n",
      "29671/29671 [==============================] - 6s 205us/step - loss: 0.0024 - accuracy: 0.4028 - val_loss: 0.0016 - val_accuracy: 0.5295\n",
      "Train on 7740 samples, validate on 832 samples\n",
      "Epoch 1/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 1.1111 - dense_1_loss: 0.0025 - dense_2_loss: 1.1082 - dense_1_accuracy: 0.3880 - dense_2_accuracy: 0.4364 - val_loss: 1.0651 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.0527 - val_dense_1_accuracy: 0.4952 - val_dense_2_accuracy: 0.4351\n",
      "Epoch 2/20\n",
      "7740/7740 [==============================] - 2s 197us/step - loss: 1.0242 - dense_1_loss: 0.0024 - dense_2_loss: 1.0213 - dense_1_accuracy: 0.3983 - dense_2_accuracy: 0.4862 - val_loss: 1.0649 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0519 - val_dense_1_accuracy: 0.4880 - val_dense_2_accuracy: 0.4399\n",
      "Epoch 3/20\n",
      "7740/7740 [==============================] - 2s 195us/step - loss: 0.9958 - dense_1_loss: 0.0024 - dense_2_loss: 0.9931 - dense_1_accuracy: 0.4018 - dense_2_accuracy: 0.5030 - val_loss: 1.0910 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0826 - val_dense_1_accuracy: 0.4988 - val_dense_2_accuracy: 0.4255\n",
      "Epoch 4/20\n",
      "7740/7740 [==============================] - 2s 194us/step - loss: 0.9768 - dense_1_loss: 0.0024 - dense_2_loss: 0.9739 - dense_1_accuracy: 0.4045 - dense_2_accuracy: 0.5207 - val_loss: 1.0760 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0593 - val_dense_1_accuracy: 0.4916 - val_dense_2_accuracy: 0.4351\n",
      "Epoch 5/20\n",
      "7740/7740 [==============================] - 2s 198us/step - loss: 0.9506 - dense_1_loss: 0.0024 - dense_2_loss: 0.9484 - dense_1_accuracy: 0.3988 - dense_2_accuracy: 0.5451 - val_loss: 1.0907 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0760 - val_dense_1_accuracy: 0.4928 - val_dense_2_accuracy: 0.4387\n",
      "Epoch 6/20\n",
      "7740/7740 [==============================] - 2s 198us/step - loss: 0.9294 - dense_1_loss: 0.0024 - dense_2_loss: 0.9270 - dense_1_accuracy: 0.3992 - dense_2_accuracy: 0.5574 - val_loss: 1.0997 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.0878 - val_dense_1_accuracy: 0.5000 - val_dense_2_accuracy: 0.4267\n",
      "Epoch 7/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 0.9096 - dense_1_loss: 0.0024 - dense_2_loss: 0.9076 - dense_1_accuracy: 0.3991 - dense_2_accuracy: 0.5693 - val_loss: 1.1434 - val_dense_1_loss: 0.0017 - val_dense_2_loss: 1.1192 - val_dense_1_accuracy: 0.4748 - val_dense_2_accuracy: 0.4423\n",
      "Epoch 8/20\n",
      "7740/7740 [==============================] - 1s 193us/step - loss: 0.8921 - dense_1_loss: 0.0024 - dense_2_loss: 0.8888 - dense_1_accuracy: 0.3901 - dense_2_accuracy: 0.5842 - val_loss: 1.1388 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1345 - val_dense_1_accuracy: 0.4663 - val_dense_2_accuracy: 0.4050\n",
      "Epoch 9/20\n",
      "7740/7740 [==============================] - 2s 196us/step - loss: 0.8657 - dense_1_loss: 0.0024 - dense_2_loss: 0.8632 - dense_1_accuracy: 0.3917 - dense_2_accuracy: 0.6019 - val_loss: 1.1466 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1426 - val_dense_1_accuracy: 0.4880 - val_dense_2_accuracy: 0.3942\n",
      "Epoch 10/20\n",
      "7740/7740 [==============================] - 2s 198us/step - loss: 0.8569 - dense_1_loss: 0.0024 - dense_2_loss: 0.8550 - dense_1_accuracy: 0.3840 - dense_2_accuracy: 0.6079 - val_loss: 1.2051 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.2156 - val_dense_1_accuracy: 0.4700 - val_dense_2_accuracy: 0.3702\n",
      "Epoch 11/20\n",
      "7740/7740 [==============================] - 2s 201us/step - loss: 0.8429 - dense_1_loss: 0.0024 - dense_2_loss: 0.8415 - dense_1_accuracy: 0.3897 - dense_2_accuracy: 0.6159 - val_loss: 1.1544 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1340 - val_dense_1_accuracy: 0.4748 - val_dense_2_accuracy: 0.4195\n",
      "Epoch 12/20\n",
      "7740/7740 [==============================] - 2s 204us/step - loss: 0.8229 - dense_1_loss: 0.0025 - dense_2_loss: 0.8202 - dense_1_accuracy: 0.3907 - dense_2_accuracy: 0.6314 - val_loss: 1.1763 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1679 - val_dense_1_accuracy: 0.4591 - val_dense_2_accuracy: 0.4147\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 190us/step - loss: 0.8043 - dense_1_loss: 0.0025 - dense_2_loss: 0.8020 - dense_1_accuracy: 0.3879 - dense_2_accuracy: 0.6443 - val_loss: 1.1799 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1698 - val_dense_1_accuracy: 0.4507 - val_dense_2_accuracy: 0.4075\n",
      "Epoch 14/20\n",
      "7740/7740 [==============================] - 2s 198us/step - loss: 0.8009 - dense_1_loss: 0.0025 - dense_2_loss: 0.7981 - dense_1_accuracy: 0.3798 - dense_2_accuracy: 0.6433 - val_loss: 1.1929 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1836 - val_dense_1_accuracy: 0.4651 - val_dense_2_accuracy: 0.4099\n",
      "Epoch 15/20\n",
      "7740/7740 [==============================] - 2s 195us/step - loss: 0.7811 - dense_1_loss: 0.0025 - dense_2_loss: 0.7800 - dense_1_accuracy: 0.3839 - dense_2_accuracy: 0.6547 - val_loss: 1.2014 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1836 - val_dense_1_accuracy: 0.4543 - val_dense_2_accuracy: 0.4219\n",
      "Epoch 16/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.7856 - dense_1_loss: 0.0025 - dense_2_loss: 0.7833 - dense_1_accuracy: 0.3831 - dense_2_accuracy: 0.6495 - val_loss: 1.2045 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.1770 - val_dense_1_accuracy: 0.4459 - val_dense_2_accuracy: 0.4183\n",
      "Epoch 17/20\n",
      "7740/7740 [==============================] - 1s 192us/step - loss: 0.7558 - dense_1_loss: 0.0025 - dense_2_loss: 0.7539 - dense_1_accuracy: 0.3760 - dense_2_accuracy: 0.6691 - val_loss: 1.2337 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.2180 - val_dense_1_accuracy: 0.4471 - val_dense_2_accuracy: 0.4399\n",
      "Epoch 18/20\n",
      "7740/7740 [==============================] - 1s 189us/step - loss: 0.7468 - dense_1_loss: 0.0025 - dense_2_loss: 0.7442 - dense_1_accuracy: 0.3801 - dense_2_accuracy: 0.6742 - val_loss: 1.2371 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.2257 - val_dense_1_accuracy: 0.4363 - val_dense_2_accuracy: 0.4099\n",
      "Epoch 19/20\n",
      "7740/7740 [==============================] - 1s 191us/step - loss: 0.7317 - dense_1_loss: 0.0025 - dense_2_loss: 0.7293 - dense_1_accuracy: 0.3871 - dense_2_accuracy: 0.6873 - val_loss: 1.2420 - val_dense_1_loss: 0.0018 - val_dense_2_loss: 1.2281 - val_dense_1_accuracy: 0.4411 - val_dense_2_accuracy: 0.4183\n",
      "Epoch 20/20\n",
      "7740/7740 [==============================] - 1s 192us/step - loss: 0.7311 - dense_1_loss: 0.0025 - dense_2_loss: 0.7296 - dense_1_accuracy: 0.3880 - dense_2_accuracy: 0.6851 - val_loss: 1.2660 - val_dense_1_loss: 0.0019 - val_dense_2_loss: 1.2342 - val_dense_1_accuracy: 0.4411 - val_dense_2_accuracy: 0.4495\n"
     ]
    }
   ],
   "source": [
    "for fi in range(1):   #Number of folds. Here I kept 1 as for demonstration\n",
    "    testing=[]\n",
    "    for sample in folds['positive'][fi]:\n",
    "        try:\n",
    "            idx=word2idx[sample]\n",
    "            testing.append([idx,[1,0,0]])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for sample in folds['negative'][fi]:\n",
    "        try:\n",
    "            idx=word2idx[sample]\n",
    "            testing.append([idx,[0,1,0]])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for sample in folds['neutral'][fi]:\n",
    "        try:\n",
    "            idx=word2idx[sample]\n",
    "            testing.append([idx,[0,0,1]])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #testing+=folds['neutral'][fi]\n",
    "    training=[]\n",
    "    for fj in range(10):\n",
    "        if fj != fi:\n",
    "            for sample in folds['positive'][fj]:\n",
    "                try:\n",
    "                    idx=word2idx[sample]\n",
    "                    training.append([idx,[1,0,0]])\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            for sample in folds['negative'][fj]:\n",
    "                try:\n",
    "                    idx=word2idx[sample]\n",
    "                    training.append([idx,[0,1,0]])\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            for sample in folds['neutral'][fj]:\n",
    "                try:\n",
    "                    idx=word2idx[sample]\n",
    "                    training.append([idx,[0,0,1]])\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            #training+=folds['neutral'][fj]\n",
    "   \n",
    "    print( \"Training fold begin\",fi)\n",
    "\n",
    "    training_labels=[]\n",
    "    testing_labels=[]\n",
    "\n",
    "    training_idx=[]\n",
    "    testing_idx=[]\n",
    "\n",
    "    training_AE=[]\n",
    "    testing_AE=[]   # = sent_vec[:TSS][:], sent_vec[TSS:][:]\n",
    "    for i in training:\n",
    "        idx=i[0]\n",
    "        training_labels.append(i[1])\n",
    "        training_AE.append(vectors[idx])\n",
    "        training_idx.append(idx)\n",
    "\n",
    "    training_AE=np.array(training_AE)\n",
    "    training_labels=np.array(training_labels)\n",
    "    training_idx=np.array(training_idx)\n",
    "\n",
    "    for i in testing:\n",
    "        idx=i[0]\n",
    "        testing_labels.append(i[1])\n",
    "        testing_AE.append(vectors[idx])\n",
    "        testing_idx.append(idx)\n",
    "\n",
    "    testing_AE=np.array(testing_AE)\n",
    "    testing_labels=np.array(testing_labels)\n",
    "    testing_idx=np.array(testing_idx)\n",
    "    #for i in range(10):\n",
    "    input_node=Input(shape=(emb,))\n",
    "    #encode=Embedding(len(word2idx), emb, weights=[vectors], input_length=1,trainable=True)(input_node)\n",
    "    encode=Reshape((1,emb))(input_node)\n",
    "    encode=Conv1D(emb,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1)(encode)\n",
    "    encode=MaxPooling1D(pool_size=1)(encode)\n",
    "    decoder=Dropout(0.2)(encode)\n",
    "    decoder=Conv1D(64,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1)(decoder)\n",
    "    decoder=GlobalMaxPooling1D()(decoder)\n",
    "    decode=Dense(emb,activation='tanh',name=\"dense_1\")(decoder)\n",
    "    \n",
    "    classifier=Conv1D(64,\n",
    "                     3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1)(encode)\n",
    "    classifier=Dropout(0.2)(classifier)\n",
    "    classifier=GlobalMaxPooling1D()(classifier)\n",
    "    senti_class=Dense(3,activation='softmax',name=\"dense_2\")(classifier)\n",
    "\n",
    "\n",
    "    encoder = Model(input_node, encode)\n",
    "    \n",
    "    autoencoder=Model(input_node,decode)\n",
    "    autoencoder.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    autoencoder.summary()\n",
    "\n",
    "    \n",
    "    combine=Model(input_node,[decode,senti_class])\n",
    "\n",
    "    losses = {\n",
    "        \"dense_1\": \"mean_squared_error\",\n",
    "        \"dense_2\": \"categorical_crossentropy\",\n",
    "    }\n",
    "    lossWeights = {\"dense_1\": 1.0, \"dense_2\": 1.0}  # Weightage for optimizing the error loss\n",
    "    combine.compile(optimizer='adam', loss=losses, loss_weights=lossWeights,\n",
    "        metrics=[\"accuracy\"])\n",
    "    combine.summary()\n",
    "    for learn in range(5):\n",
    "        autoencoder.fit(train, train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test, test))\n",
    "                    \n",
    "        combine.fit(training_AE, [training_AE, training_labels],\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(testing_AE, [testing_AE, testing_labels]))\n",
    "    \n",
    "    model_json = combine.to_json()\n",
    "    with open(\"model/senti_autoencoder_combine_\"+str(fi)+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    combine.save_weights(\"model/senti_autoencoder_combine_\"+str(fi)+\".h5\")\n",
    "\n",
    "    model_json = encoder.to_json()\n",
    "    with open(\"model/3class_encoder_\"+str(fi)+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    encoder.save_weights(\"model/3class_encoder_\"+str(fi)+\".h5\")\n",
    "    \n",
    "        \n",
    "    f2=open('model/SHE_encoder_out_'+str(fi)+'emb','w')\n",
    "    f2.write(str(len(word2idx))+' '+str(emb)+'\\n')\n",
    "    for key in word2idx:\n",
    "        f2.write(key.replace(' ','')+\" \")\n",
    "        w2v=model[key]\n",
    "        result=encoder.predict(np.asarray([w2v]),verbose=0)\n",
    "        for i in list(result[0][0]):\n",
    "            f2.write(str(i)+\" \")\n",
    "        f2.write(\"\\n\")\n",
    "    f2.close()\n",
    "\n",
    "    \n",
    "    del input_node\n",
    "    del encode\n",
    "    del classifier\n",
    "    del senti_class\n",
    "    del autoencoder\n",
    "    del combine\n",
    "    gc.collect()   \n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the SHE trained embedding from the best performaning fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f2=open('emb/SHE_encoder_out.emb','w')\n",
    "# f2.write(str(len(word2idx))+' '+str(emb)+'\\n')\n",
    "# for key in word2idx:\n",
    "#     f2.write(key.replace(' ','')+\" \")\n",
    "#     w2v=model[key]\n",
    "#     result=encoder.predict(np.asarray([w2v]),verbose=0)\n",
    "#     for i in list(result[0][0]):\n",
    "#         f2.write(str(i)+\" \")\n",
    "#     f2.write(\"\\n\")\n",
    "# f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
